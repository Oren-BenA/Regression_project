{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dv5r5YCyPWWW"
   },
   "source": [
    "imports    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement scikit-learn1 (from versions: none)\n",
      "ERROR: No matching distribution found for scikit-learn1\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1691941870862,
     "user": {
      "displayName": "Gilad Danin",
      "userId": "00864302539574052919"
     },
     "user_tz": -180
    },
    "id": "q83U1-BC4liK"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PolynomialFeatures\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Lasso\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\eda\\Lib\\site-packages\\sklearn\\__init__.py:83\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     80\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     81\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     )\n\u001b[1;32m---> 83\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[0;32m     86\u001b[0m     __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    130\u001b[0m     ]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\eda\\Lib\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\eda\\Lib\\site-packages\\sklearn\\utils\\__init__.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclass_weight\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_class_weight, compute_sample_weight\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\eda\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mInvalidParameterError\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    does not have a valid type or value.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\eda\\Lib\\site-packages\\sklearn\\utils\\validation.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config \u001b[38;5;28;01mas\u001b[39;00m _get_config\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning, NotFittedError, PositiveSpectrumWarning\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _asarray_with_order, _is_numpy_namespace, get_namespace\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_isfinite\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FiniteStatus, cy_isfinite\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _object_dtype_isnan\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\eda\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mspecial\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_version\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_array_api_dispatch\u001b[39m(array_api_dispatch):\n\u001b[0;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that array_api_compat is installed and NumPy version is compatible.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    array_api_compat follows NEP29, which has a higher minimum NumPy version than\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    scikit-learn.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\eda\\Lib\\site-packages\\sklearn\\utils\\fixes.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreadpoolctl\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\eda\\Lib\\site-packages\\scipy\\stats\\__init__.py:608\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m \n\u001b[0;32m    604\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_warnings_errors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[0;32m    607\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[1;32m--> 608\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\eda\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mspecial\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linalg\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distributions\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _mstats_basic \u001b[38;5;28;01mas\u001b[39;00m mstats_basic\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_mstats_common\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (_find_repeats, linregress, theilslopes,\n\u001b[0;32m     49\u001b[0m                                    siegelslopes)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\eda\\Lib\\site-packages\\scipy\\stats\\distributions.py:8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Author:  Travis Oliphant  2002-2011 with contributions from\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#          SciPy Developers 2004-2011\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#       instead of `git blame -Lxxx,+x`.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_distn_infrastructure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (rv_discrete, rv_continuous, rv_frozen)  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _continuous_distns\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _discrete_distns\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\eda\\Lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:23\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m comb, entr\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# for root finding for continuous distribution ppf, and maximum likelihood\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# estimation\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimize\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# for functions of continuous distributions (e.g. moments, entropy, cdf)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m integrate\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1231\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\eda\\Lib\\site-packages\\scipy\\__init__.py:204\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m submodules:\n\u001b[1;32m--> 204\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_importlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscipy.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\eda\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\eda\\Lib\\site-packages\\scipy\\optimize\\__init__.py:420\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_nonlin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_slsqp_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin_slsqp\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_nnls\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nnls\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_basinhopping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m basinhopping\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_linprog\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linprog, linprog_verbose_callback\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\eda\\Lib\\site-packages\\scipy\\optimize\\_nnls.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __nnls\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m asarray_chkfinite, zeros, double\n\u001b[0;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnnls\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# None linear\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as rmse\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "from math import ceil\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1691941870862,
     "user": {
      "displayName": "Gilad Danin",
      "userId": "00864302539574052919"
     },
     "user_tz": -180
    },
    "id": "q83U1-BC4liK"
   },
   "outputs": [],
   "source": [
    "# None linear\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as rmse\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "from math import ceil\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSTp2n-0Pmyo"
   },
   "source": [
    "Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1691941872676,
     "user": {
      "displayName": "Gilad Danin",
      "userId": "00864302539574052919"
     },
     "user_tz": -180
    },
    "id": "cEjD3pfVLoSk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def get_permutations(config_dic):\n",
    "# Get values for each key\n",
    "    values = config_dic.values()\n",
    "    pairs = []\n",
    "# Generate pairs of values\n",
    "    for combination in itertools.product(*values):\n",
    "        pairs.append(list(combination))\n",
    "\n",
    "# Display the pairs\n",
    "    permute_dics = []\n",
    "    for pair in pairs:\n",
    "        permute_dics.append({k: v for k, v in zip(config_dic.keys(), pair)})\n",
    "\n",
    "    return permute_dics\n",
    "\n",
    "def print_dict_verticaly(dict_):\n",
    "  for key, value in dict_.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "def print_list_vertically(list_):\n",
    "  vertical_string = '\\n'.join(str(element) for element in list_)\n",
    "  print(vertical_string)\n",
    "\n",
    "def filter_func_params(func_params,params):\n",
    "  params_filtered = {}\n",
    "  for name in params:\n",
    "    if (name in func_params):\n",
    "      params_filtered.update({name: params[name]})\n",
    "\n",
    "  return params_filtered\n",
    "\n",
    "def generate_colors(num_colors):\n",
    "    cmap = plt.get_cmap('tab10')  # You can use different colormaps like 'tab10', 'viridis', 'Set1', etc.\n",
    "    colors = [cmap(i) for i in range(num_colors)]\n",
    "    return colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1691941872676,
     "user": {
      "displayName": "Gilad Danin",
      "userId": "00864302539574052919"
     },
     "user_tz": -180
    },
    "id": "cEjD3pfVLoSk"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def get_permutations(config_dic):\n",
    "# Get values for each key\n",
    "    values = config_dic.values()\n",
    "    pairs = []\n",
    "# Generate pairs of values\n",
    "    for combination in itertools.product(*values):\n",
    "        pairs.append(list(combination))\n",
    "\n",
    "# Display the pairs\n",
    "    permute_dics = []\n",
    "    for pair in pairs:\n",
    "        permute_dics.append({k: v for k, v in zip(config_dic.keys(), pair)})\n",
    "\n",
    "    return permute_dics\n",
    "\n",
    "def print_dict_verticaly(dict_):\n",
    "  for key, value in dict_.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "def print_list_vertically(list_):\n",
    "  vertical_string = '\\n'.join(str(element) for element in list_)\n",
    "  print(vertical_string)\n",
    "\n",
    "def filter_func_params(func_params,params):\n",
    "  params_filtered = {}\n",
    "  for name in params:\n",
    "    if (name in func_params):\n",
    "      params_filtered.update({name: params[name]})\n",
    "\n",
    "  return params_filtered\n",
    "\n",
    "def generate_colors(num_colors):\n",
    "    cmap = plt.get_cmap('tab10')  # You can use different colormaps like 'tab10', 'viridis', 'Set1', etc.\n",
    "    colors = [cmap(i) for i in range(num_colors)]\n",
    "    return colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKnrruGTQDQd"
   },
   "source": [
    "PREDICTOR class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1691941872677,
     "user": {
      "displayName": "Gilad Danin",
      "userId": "00864302539574052919"
     },
     "user_tz": -180
    },
    "id": "W58DeV91GzAc"
   },
   "outputs": [],
   "source": [
    "class PREDICTOR():\n",
    "    def __init__(self,name = None):\n",
    "      self.model = None\n",
    "      self.name = name\n",
    "      self.params = None\n",
    "      self.stats = {}\n",
    "\n",
    "    def train_test_split(X,y):\n",
    "      X_train, X_test, y_train, y_test = train_test_split(\n",
    "          X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "      return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "    def fit(self, X, y,type,params={}):\n",
    "      if (len(params)==0):\n",
    "        params = {}\n",
    "      self.params = params\n",
    "\n",
    "      if (1):\n",
    "      # try:\n",
    "        if (type=='linear_regression'):\n",
    "          params_filtered = filter_func_params(LinearRegression().get_params(),params)\n",
    "          self.model = LinearRegression(**params_filtered)\n",
    "\n",
    "        elif (type=='decision_tree'):\n",
    "          params_filtered = filter_func_params(DecisionTreeRegressor().get_params(),params)\n",
    "          self.model = DecisionTreeRegressor(**params_filtered)\n",
    "\n",
    "        elif (type=='knn'):\n",
    "          params_filtered = filter_func_params(KNeighborsRegressor().get_params(),params)\n",
    "          self.model = KNeighborsRegressor(**params_filtered)\n",
    "            \n",
    "        elif (type=='lasso'):\n",
    "          params_filtered = filter_func_params(Lasso().get_params(),params)\n",
    "          self.model = Lasso(**params_filtered)\n",
    "                \n",
    "        elif (type=='ridge'):\n",
    "          params_filtered = filter_func_params(Ridge().get_params(),params)\n",
    "          self.model = Ridge(**params_filtered)                \n",
    "            \n",
    "        self.model.fit(X, y)\n",
    "      return 1\n",
    "\n",
    "      # except:\n",
    "      #   print(f'{type} fit failed due to wrong parameterization:{params}')\n",
    "      #   return 0\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = self.model.predict(X)        \n",
    "        return y_pred\n",
    "\n",
    "\n",
    "    def plot_prediction(self,X,y,y_pred=None,axes=None):\n",
    "        print('kuku')\n",
    "        if (axes is None):\n",
    "            fig, axes = plt.subplots(nrows=1, ncols=1)\n",
    "\n",
    "        if (y_pred is None):\n",
    "            y_pred = self.predict(X)\n",
    "\n",
    "        axes.scatter(y, y_pred, color='blue', label='Actual Data',s=5)\n",
    "        \n",
    "        axes.legend()\n",
    "        params_string = self.create_params_string()\n",
    "        axes.set_title(self.name+':'+params_string,fontsize=8)\n",
    "        x_limits = axes.get_xlim()\n",
    "        y_limits = axes.get_ylim()\n",
    "        x_corr = abs(x_limits[1]-x_limits[0])*0.9+x_limits[0]\n",
    "        y_corr = abs(y_limits[1]-y_limits[0])*0.1+y_limits[0]\n",
    "        RMSE = self.evaluate(y,y_pred)\n",
    "        axes.text(x_corr,y_corr,f'RMSE={RMSE:.3f}',horizontalalignment='center',fontsize=8)\n",
    "\n",
    "    def evaluate(self,y, y_pred,str=''):\n",
    "        if (str != ''):\n",
    "          str = '_' + str\n",
    "        self.stats.update({'rmse'+str:rmse(y, y_pred)})\n",
    "        return self.stats\n",
    "\n",
    "    def create_params_string(self):\n",
    "      params_string = ''\n",
    "      for key, value in self.params.items():\n",
    "        params_string = params_string+f'{key}={value}'\n",
    "      return params_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjFbMZFJP4DF"
   },
   "source": [
    "AI_PIPE_LINE class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1691942016158,
     "user": {
      "displayName": "Gilad Danin",
      "userId": "00864302539574052919"
     },
     "user_tz": -180
    },
    "id": "ME6qF_wRzHRq"
   },
   "outputs": [],
   "source": [
    "class AI_PIPE_LINE():\n",
    "  def __init__(self,name = None):\n",
    "    self.df = None\n",
    "    self.params_permutes_dic = None\n",
    "    self.predictors = {}\n",
    "    self.stats = {}\n",
    "\n",
    "  def prepare_data(self,df):\n",
    "    self.df = df\n",
    "\n",
    "  def train_test_split(self,X_columns,y_column,params={}):\n",
    "    # params_filtered = filter_func_params(train_test_split().get_params(),params)\n",
    "    params_filtered = {}\n",
    "    X = self.df[X_columns]\n",
    "    # if (len(X_columns)==1):\n",
    "    #   X = X.reshape(-1,1)\n",
    "\n",
    "    y = self.df[y_column]\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,**params_filtered)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "  def get_permutations(self,config_dic):\n",
    "  # Get values for each key\n",
    "      values = config_dic.values()\n",
    "      pairs = []\n",
    "\n",
    "  # Generate pairs of values\n",
    "      for combination in itertools.product(*values):\n",
    "          pairs.append(list(combination))\n",
    "\n",
    "  # Display the pairs\n",
    "      params_permutes_dic = []\n",
    "      for pair in pairs:\n",
    "          params_permutes_dic.append({k: v for k, v in zip(config_dic.keys(), pair)})\n",
    "\n",
    "      self.params_permutes_dic = params_permutes_dic\n",
    "      return params_permutes_dic\n",
    "\n",
    "  def add_predictor(self,name=None):\n",
    "    if (name is None):\n",
    "      name = f'model_{len(self.predictors)}'\n",
    "\n",
    "    predictor = PREDICTOR(name)\n",
    "    self.predictors.update({name:predictor})\n",
    "    return predictor\n",
    "\n",
    "\n",
    "\n",
    "  def get_stats(self,stat_names=None):\n",
    "    stats = {}\n",
    "\n",
    "    for stat_name in stat_names:\n",
    "      stats.update({stat_name:[]})\n",
    "      for name in self.predictors.keys():\n",
    "        stats_pred = self.predictors[name].stats\n",
    "        stats[stat_name].append(stats_pred[stat_name])\n",
    "\n",
    "      self.stats = stats\n",
    "    return stats\n",
    "\n",
    "\n",
    "  def plot_stats(self,stats_names):\n",
    "    fig = plt.figure()\n",
    "    colors = generate_colors(len(stats_names))\n",
    "    idx = 0\n",
    "    for stat_name in stats_names:\n",
    "      stat = self.stats[stat_name]\n",
    "      plt.plot(stat,color=colors[idx])\n",
    "      idx+=1\n",
    "\n",
    "    plt.legend(stats_names)\n",
    "    \n",
    "    def filter_predictors(self, filter_dic):\n",
    "        filtered_predictor = self.predictors\n",
    "        return filtered_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLIuGw9YQJB0"
   },
   "source": [
    "Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"./data/X.csv\"\n",
    "X = pd.read_csv(file_path)\n",
    "\n",
    "file_path = \"./data/y.csv\"\n",
    "y = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 4227,
     "status": "ok",
     "timestamp": 1691942020380,
     "user": {
      "displayName": "Gilad Danin",
      "userId": "00864302539574052919"
     },
     "user_tz": -180
    },
    "id": "Dar8D3i1Mcu2",
    "outputId": "37314506-8702-46f7-d739-bdaa46f0c7bf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = X.join(y.set_index('id'))\n",
    "\n",
    "df_mod = df\n",
    "\n",
    "# clear all null lines\n",
    "for column in df_mod.columns:\n",
    "    nulls_mask = df_mod[column].notnull()  # or column_with_nulls.isna()\n",
    "    df_mod = df_mod[nulls_mask]\n",
    "\n",
    "# rename unnamed columns\n",
    "df_mod.rename(columns={'Unnamed: 0.1': 'col1'}, inplace=True)\n",
    "df_mod.drop(columns='Unnamed: 0', inplace=True)\n",
    "\n",
    "# deal with categorial columns\n",
    "\n",
    "# get all relevant column names\n",
    "categorical_columns = df_mod.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "drop_categorial = True\n",
    "if (drop_categorial):\n",
    "    df_mod = df_mod.drop(columns=categorical_columns)\n",
    "else:\n",
    "    # drop some of them\n",
    "    categorical_columns_remove = 'Job Title'\n",
    "    categorical_columns = [item for item in categorical_columns if item != categorical_columns_remove]\n",
    "\n",
    "\n",
    "    df_mod = pd.get_dummies(df_mod,columns = categorical_columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = df_mod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "aborted",
     "timestamp": 1691941872683,
     "user": {
      "displayName": "Gilad Danin",
      "userId": "00864302539574052919"
     },
     "user_tz": -180
    },
    "id": "6Ffx6sex8uBO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "AI_pipe_line = AI_PIPE_LINE()\n",
    "\n",
    "AI_pipe_line.prepare_data(df)\n",
    "\n",
    "X_columns = df.columns.drop('Salary')\n",
    "X_columns = [item for item in df.columns if item not in categorical_columns]\n",
    "\n",
    "y_cloumn = 'Salary'\n",
    "\n",
    "# linear regression on single features\n",
    "params_config_dic = {\n",
    "                     'model_type':['linear_regression'],\n",
    "                     'random_state':[0],\n",
    "                     'X_columns':X_columns\n",
    "                     }\n",
    "\n",
    "params_permutes_list = AI_pipe_line.get_permutations(params_config_dic)\n",
    "# Lasso regression on multiple featrures\n",
    "\n",
    "params_config_dic = {\n",
    "                     'model_type':['lasso'],\n",
    "                     'random_state':[0],\n",
    "                     'X_columns':X_columns\n",
    "                     }\n",
    "\n",
    "params_permutes_list = AI_pipe_line.get_permutations(params_config_dic)\n",
    "\n",
    "\n",
    "# split to train and test\n",
    "\n",
    "\n",
    "\n",
    "for params_dic in params_permutes_list:\n",
    "    X_train, X_test, y_train, y_test = AI_pipe_line.train_test_split(X_columns,y_cloumn)\n",
    "\n",
    "    # create predictor\n",
    "    predictor = AI_pipe_line.add_predictor()\n",
    "\n",
    "    # fit model\n",
    "    predictor.fit(X_train, y_train,params_dic['model_type'],params_dic)\n",
    "\n",
    "    # predict and eval on train\n",
    "    y_train_predict = predictor.predict(X_train)\n",
    "    stats = predictor.evaluate(y_train,y_train_predict,'train')\n",
    "\n",
    "    # predict and eval on test\n",
    "    y_test_predict = predictor.predict(X_test)\n",
    "    stats = predictor.evaluate(y_test,y_test_predict,'test')\n",
    "\n",
    "\n",
    "# filter the predictors\n",
    "# predictors_filter = {'model_type':'linear_regression'}    \n",
    "    \n",
    "# collect the stats from all the predictors\n",
    "stats = AI_pipe_line.get_stats(['rmse_train','rmse_test'])\n",
    "\n",
    "AI_pipe_line.plot_stats(stats_names=['rmse_train','rmse_test'])\n",
    "\n",
    "AI_pipe_line.predictors['model_0'].plot_prediction(X_test,y_test,axes=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AI_pipe_line.predictors['model_0'].plot_prediction(X_test,y_test,axes=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AI_pipe_line.predictors\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
